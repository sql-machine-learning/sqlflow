syntax = "proto3";

import "google/protobuf/any.proto";

package proto;

service SQLFlow {
    // Run executes a sql statement
    //
    // SQL statements like `SELECT ...`, `DESCRIBE ...` returns a rowset.
    // The rowset might be big. In such cases, Query returns a stream
    // of RunResponse
    // 
    // SQLFlow implements the Run interface with two mode:
    //
    // 1. Local model
    // The SQLFlow server execute the SQL statements on the local host.
    // 
    // SQL statements like `USE database`, `DELETE` returns only a success
    // message.
    //
    // SQL statement like `SELECT ... TO TRAIN/PREDICT ...` returns a stream of
    // messages which indicates the training/predicting progress
    // 
    // 2. Argo Workflow mode
    // The SQLFlow server submits an Argo workflow into a Kubernetes cluster,
    // and returns a stream of messages indicates the WorkFlow ID and the 
    // submitting progress.
    //
    // The SQLFlow gRPC client should fetch the logs of the workflow by
    // calling the Fetch interface in a polling manner.
    rpc Run (Request) returns (stream Response);

    // Fetch fetches the SQLFlow job phase and logs in a polling manner. A corresponding
    // client can be implemented as
    //
    // wfJob := Submit(argoYAML)
    // req := &FetchRequest {
    //   Job : { Id: wfJob },
    // }
    // for {
    //   res := Fetch(req)
    //   fmt.Println(res.Logs)
    //   if isComplete(res) {
    //     break
    //   }
    //   req = res.UpdatedFetchSince
    //   time.Sleep(time.Second)
    // }
    //
    rpc Fetch (FetchRequest) returns (FetchResponse);
}

message Job {
    string id = 1;
}

message FetchRequest {
    Job job = 1;
    // the following fields keep the fetching state
    string step_id = 2;
    string step_phase = 3;
}

message FetchResponse {
    message Responses {
        repeated Response response = 1;
    }
    FetchRequest updated_fetch_since = 1;
    bool eof = 2;
    Responses responses = 4;
}

message Session {
    string token = 1;
    string db_conn_str = 2;
    bool exit_on_submit = 3;
    string user_id = 4;
    // for loading CSV to hive
    string hive_location = 5;
    string hdfs_namenode_addr = 6;
    string hdfs_user = 7;
    string hdfs_pass = 8;
    string submitter = 9;
}

// SQL statements to run
// e.g.
//      1. `SELECT ...`
//      2. `USE ...`, `DELETE ...`
//      3. `SELECT ... TO TRAIN/PREDICT ...`
message Request {
    string sql = 1;      // The SQL statement to be executed.
    Session session = 2;
}

message Response {
    oneof response {
        Head head = 1;
        Row row = 2;
        Message message = 3;
        EndOfExecution eoe = 4;
        Job job = 5;
    }
}

// SQL statements like `SELECT ...`, `DESCRIBE ...` returns a Head
// and a sequence of Rows
message Head {
    repeated string column_names = 1;
}

message Row {
    // Null is a special marker used in Structured Query Language to indicate
    // that a data value does not exist in the database.
    // We encoded this marker as message Null, and it is one possible type of
    // google.protobuf.Any in the field data
    message Null {}
    repeated google.protobuf.Any data = 1;
}

// SQL statements like `USE database`, `DELETE` returns only a success
// message.
//
// SQL statement like `SELECT ... TO TRAIN/PREDICT ...` returns a stream of
// messages which indicates the training/predicting progress
message Message {
  string message = 1;
}

// SQLFlow server may execute multiple SQL statements in one RPC call.
// EndOfExecution message tells the client that execution of one SQL is
// finished, the client should go to next loop to parse the result stream.
message EndOfExecution {
    string sql = 1;
    int64 spent_time_seconds = 2;
}
